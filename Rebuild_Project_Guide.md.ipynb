{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project Configurations\n",
    "```\n",
    "# Runtime params\n",
    "#===================================\n",
    "train: True # train new or existing model for each channel\n",
    "predict: True # generate new predicts or, if False, use predictions stored locally\n",
    "use_id: \"2018-05-19_15.00.10\"\n",
    "\n",
    "# number of values to evaluate in each batch\n",
    "batch_size: 70\n",
    "\n",
    "# number of trailing batches to use in error calculation\n",
    "window_size: 30\n",
    "\n",
    "# Columns headers for output file\n",
    "header: [\"run_id\", \"chan_id\", \"spacecraft\", \"num_anoms\", \"anomaly_sequences\", \"class\", \"true_positives\", \n",
    "        \"false_positives\", \"false_negatives\", \"tp_sequences\", \"fp_sequences\", \"gaussian_p-value\", \"num_values\",\n",
    "        \"normalized_error\", \"eval_time\", \"scores\"]\n",
    "\n",
    "# determines window size used in EWMA smoothing (percentage of total values for channel)\n",
    "smoothing_perc: 0.05\n",
    "\n",
    "# number of values surrounding an error that are brought into the sequence (promotes grouping on nearby sequences\n",
    "error_buffer: 100\n",
    "\n",
    "# LSTM parameters\n",
    "# ==================================\n",
    "loss_metric: 'mse'\n",
    "optimizer: 'adam'\n",
    "validation_split: 0.2\n",
    "dropout: 0.3\n",
    "lstm_batch_size: 64\n",
    "\n",
    "# maximum number of epochs allowed (if early stopping criteria not met)\n",
    "epochs: 35\n",
    "\n",
    "# network architecture [<neurons in hidden layer>, <neurons in hidden layer>]\n",
    "# Size of input layer not listed - dependent on evr modules and types included (see 'evr_modules' and 'erv_types' above)\n",
    "layers: [80,80]\n",
    "\n",
    "# Number of consequetive training iterations to allow without decreasing the val_loss by at least min_delta \n",
    "patience: 10\n",
    "min_delta: 0.0003\n",
    "\n",
    "# num previous timesteps provided to model to predict future values\n",
    "l_s: 250\n",
    "\n",
    "# number of steps ahead to predict\n",
    "n_predictions: 10\n",
    "\n",
    "# Error thresholding parameters\n",
    "# ==================================\n",
    "\n",
    "# minimum percent decrease between max errors in anomalous sequences (used for pruning)\n",
    "p: 0.13\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step by Step:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. load data one by one according to the row in the labeled_anomalies.csv\n",
    "2. for each set of data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Load Data\n",
    "For example:\n",
    "\n",
    "##### l_s = 250 (num previous timesteps provided to model to predict future values), \n",
    "##### n_predictions = 10 (number of steps ahead to predictï¼‰\n",
    "data = [] \n",
    "for i in range(len(arr) - config.l_s - config.n_predictions):\n",
    "    data.append(arr[i:i + config.l_s + config.n_predictions])\n",
    "    \n",
    "Thus:    \n",
    "train_shape: (2872, 25), X_train_shape: (2612, 250, 25), y_train_shape: (2612, 10)\n",
    "X_test_shape: (8245, 250, 25), y_test_shape: (8245, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Train Model\n",
    "```\n",
    "def get_model(anom, X_train, y_train, logger, train=False):\n",
    "    '''Train LSTM model according to specifications in config.yaml or load pre-trained model.\n",
    "\n",
    "    Args:\n",
    "        anom (dict): contains all anomaly information for a given input stream\n",
    "        X_train (np array): numpy array of training inputs with dimensions [timesteps, l_s, input dimensions)\n",
    "        y_train (np array): numpy array of training outputs corresponding to true values following each sequence\n",
    "        logger (obj): logging object\n",
    "        train (bool): If False, will attempt to load existing model from repo\n",
    "\n",
    "    Returns:\n",
    "        model (obj): Trained Keras LSTM model \n",
    "    '''\n",
    "\n",
    "    if not train and os.path.exists(os.path.join(\"data\", config.use_id, \"models\", anom[\"chan_id\"] + \".h5\")):\n",
    "        logger.info(\"Loading pre-trained model\")\n",
    "        return load_model(os.path.join(\"data\", config.use_id, \"models\", anom[\"chan_id\"] + \".h5\"))\n",
    "\n",
    "    elif (not train and not os.path.exists(os.path.join(\"data\", config.use_id, \"models\", anom[\"chan_id\"] + \".h5\"))) or train:\n",
    "        \n",
    "        if not train:\n",
    "            logger.info(\"Training new model from scratch.\")\n",
    "\n",
    "        cbs = [History(), EarlyStopping(monitor='val_loss', patience=config.patience, \n",
    "            min_delta=config.min_delta, verbose=0)]\n",
    "        \n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(LSTM(\n",
    "            config.layers[0],\n",
    "            input_shape=(None, X_train.shape[2]),\n",
    "            return_sequences=True))\n",
    "        model.add(Dropout(config.dropout))\n",
    "\n",
    "        model.add(LSTM(\n",
    "            config.layers[1],\n",
    "            return_sequences=False))\n",
    "        model.add(Dropout(config.dropout))\n",
    "\n",
    "        model.add(Dense(\n",
    "            config.n_predictions))\n",
    "        model.add(Activation(\"linear\"))\n",
    "\n",
    "        model.compile(loss=config.loss_metric, optimizer=config.optimizer) \n",
    "\n",
    "        model.fit(X_train, y_train, batch_size=config.lstm_batch_size, epochs=config.epochs, \n",
    "            validation_split=config.validation_split, callbacks=cbs, verbose=True)\n",
    "        model.save(os.path.join(\"data\", anom['run_id'], \"models\", anom[\"chan_id\"] + \".h5\"))\n",
    "\n",
    "        return model\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
